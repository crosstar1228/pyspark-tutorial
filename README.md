# pyspark-tutorial
A diary of my learning journey into the world of Apache Spark (pyspark) from an ETL-developer perspective

To follow my journey you will need:
* openjdk-1.8.0_242
* spark-2.4.5                 
* python3.7.7
* Python packages (ref. Pipfile)
  * findspark
  * jupyter
  * numpy
  * pandas
  * pypandoc
  * pyspark2.4.5

My learning path:
* Day 1: Installing a local Spark environment
* Day 2: My first Spark application and some basic concepts
* Day 3: Taking a deeper insight into DataFrames
* Day 4: Getting an Overview on the pyspark.sql module
* Day 5: Doing some math and aggregations
* Day 6: Tackling the date and time challenge
* Day 7: Handling of NULL values
* Day 8: JSON and complex data types to analyse semi-/unstructured data
* Day 9: Joins
